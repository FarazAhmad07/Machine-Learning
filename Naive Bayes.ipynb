{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier Algorithm\n",
    "\n",
    "#### Naïve Bayes algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems.\n",
    "\n",
    "#### It is mainly used in text classification that includes a high-dimensional training dataset.\n",
    "\n",
    "#### Naïve Bayes Classifier is one of the simple and most effective Classification algorithms which helps in building the fast machine learning models that can make quick predictions.\n",
    "\n",
    "#### It is a probabilistic classifier, which means it predicts on the basis of the probability of an object.\n",
    "\n",
    "#### Some popular examples of Naïve Bayes Algorithm are spam filtration, Sentimental analysis, and classifying articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is it called Naïve Bayes?\n",
    "\n",
    "#### The Naïve Bayes algorithm is comprised of two words Naïve and Bayes, Which can be described as:\n",
    "\n",
    "#### Naïve: It is called Naïve because it assumes that the occurrence of a certain feature is independent of the occurrence of other features. Such as if the fruit is identified on the bases of color, shape, and taste, then red, spherical, and sweet fruit is recognized as an apple. Hence each feature individually contributes to identify that it is an apple without depending on each other.\n",
    "\n",
    "#### Bayes: It is called Bayes because it depends on the principle of Bayes' Theorem."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' Theorem:\n",
    "\n",
    "#### Bayes' theorem is also known as Bayes' Rule or Bayes' law, which is used to determine the probability of a hypothesis with prior knowledge. It depends on the conditional probability.\n",
    "#### The formula for Bayes' theorem is given as:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "#### Naïve Bayes Classifier Algorithm\n",
    "\n",
    "Where,\n",
    "\n",
    "P(A|B) is Posterior probability: Probability of hypothesis A on the observed event B.\n",
    "\n",
    "P(B|A) is Likelihood probability: Probability of the evidence given that the probability of a hypothesis is true.\n",
    "\n",
    "P(A) is Prior Probability: Probability of hypothesis before observing the evidence.\n",
    "\n",
    "P(B) is Marginal Probability: Probability of Evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working of Naïve Bayes' Classifier:\n",
    "\n",
    "#### Working of Naïve Bayes' Classifier can be understood with the help of the below example:\n",
    "\n",
    "#### Suppose we have a dataset of weather conditions and corresponding target variable \"Play\". So using this dataset we need to decide that whether we should play or not on a particular day according to the weather conditions. So to solve this problem, we need to follow the below steps:\n",
    "\n",
    "#### Convert the given dataset into frequency tables.\n",
    "#### Generate Likelihood table by finding the probabilities of given features.\n",
    "#### Now, use Bayes theorem to calculate the posterior probability.\n",
    "\n",
    "Problem: If the weather is sunny, then the Player should play or not?\n",
    "\n",
    "Solution: To solve this, first consider the below dataset:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\tOutlook\t Play\n",
    "0\tRainy\t Yes\n",
    "1\tSunny\t Yes\n",
    "2\tOvercast Yes\n",
    "3\tOvercast Yes\n",
    "4\tSunny\t No\n",
    "5\tRainy\t Yes\n",
    "6\tSunny\t Yes\n",
    "7\tOvercast Yes\n",
    "8\tRainy\t No\n",
    "9\tSunny\t No\n",
    "10\tSunny\t Yes\n",
    "11\tRainy\t No\n",
    "12\tOvercast Yes\n",
    "13\tOvercast Yes\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Frequency table for the Weather Conditions:\n",
    "\n",
    "Weather\tYes\tNo\n",
    "Overcast 5\t0\n",
    "Rainy\t 2\t2\n",
    "Sunny\t 3\t2\n",
    "Total\t10\t4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Likelihood table weather condition:\n",
    "\n",
    "Weather\t   No\tYes\t\n",
    "Overcast\t0\t 5\t       5/14= 0.35\n",
    "Rainy\t    2\t 2\t       4/14=0.29\n",
    "Sunny\t    2\t 3\t       5/14=0.35\n",
    "All\t 4/14=0.29 10/14=0.71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Bayes'theorem:\n",
    "\n",
    "P(Yes|Sunny)= P(Sunny|Yes)*P(Yes)/P(Sunny)\n",
    "\n",
    "P(Sunny|Yes)= 3/10= 0.3\n",
    "\n",
    "P(Sunny)= 0.35\n",
    "\n",
    "P(Yes)=0.71\n",
    "\n",
    "So P(Yes|Sunny) = 0.3*0.71/0.35= 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(No|Sunny)= P(Sunny|No)*P(No)/P(Sunny)\n",
    "\n",
    "P(Sunny|NO)= 2/4=0.5\n",
    "\n",
    "P(No)= 0.29\n",
    "\n",
    "P(Sunny)= 0.35\n",
    "\n",
    "So P(No|Sunny)= 0.5*0.29/0.35 = 0.41\n",
    "\n",
    "So as we can see from the above calculation that P(Yes|Sunny)>P(No|Sunny)\n",
    "### Hence on a Sunny day, Player can play the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "Precision: 1.0\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Your data\n",
    "data = {\n",
    "    'Outlook': ['Rainy', 'Sunny', 'Overcast', 'Overcast', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Rainy', 'Sunny', 'Sunny', 'Rainy', 'Overcast', 'Overcast'],\n",
    "    'Play': ['Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert categorical variables to numeric\n",
    "le = LabelEncoder()\n",
    "df['Outlook'] = le.fit_transform(df['Outlook'])\n",
    "df['Play'] = le.fit_transform(df['Play'])\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df[['Outlook']]\n",
    "y = df['Play']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9292\n",
      "Test Precision: 0.9318\n",
      "Test Recall: 0.9292\n",
      "Test F1 Score: 0.9294\n",
      "Cross-Validation Accuracy: 0.9409 (+/- 0.0428)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load data from CSV file\n",
    "file_path = 'DataUpdated.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop('RV', axis=1)  # Features\n",
    "y = data['RV']  # Target variable\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)\n",
    "\n",
    "# Create a Naive Bayes Classifier (Gaussian Naive Bayes)\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on test set\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1-score for test set\n",
    "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
    "recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
    "f1_score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_accuracy = cross_val_score(clf, X_scaled, y, cv=10, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {cv_accuracy.mean():.4f} (+/- {cv_accuracy.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9429\n",
      "Training Precision: 0.9429\n",
      "Training Recall: 0.9429\n",
      "Training F1 Score: 0.9429\n",
      "Test Accuracy: 0.9778\n",
      "Test Precision: 0.9794\n",
      "Test Recall: 0.9778\n",
      "Test F1 Score: 0.9777\n",
      "Fold 1 - Train Accuracy: 0.9630, Precision: 0.9631, Recall: 0.9630, F1 Score: 0.9630\n",
      "Fold 1 - Test Accuracy: 0.9333, Precision: 0.9444, Recall: 0.9333, F1 Score: 0.9327\n",
      "Fold 2 - Train Accuracy: 0.9556, Precision: 0.9556, Recall: 0.9556, F1 Score: 0.9556\n",
      "Fold 2 - Test Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Fold 3 - Train Accuracy: 0.9481, Precision: 0.9483, Recall: 0.9481, F1 Score: 0.9481\n",
      "Fold 3 - Test Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Fold 4 - Train Accuracy: 0.9630, Precision: 0.9631, Recall: 0.9630, F1 Score: 0.9630\n",
      "Fold 4 - Test Accuracy: 0.9333, Precision: 0.9444, Recall: 0.9333, F1 Score: 0.9327\n",
      "Fold 5 - Train Accuracy: 0.9630, Precision: 0.9631, Recall: 0.9630, F1 Score: 0.9630\n",
      "Fold 5 - Test Accuracy: 0.8667, Precision: 0.8667, Recall: 0.8667, F1 Score: 0.8667\n",
      "Fold 6 - Train Accuracy: 0.9556, Precision: 0.9556, Recall: 0.9556, F1 Score: 0.9556\n",
      "Fold 6 - Test Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Fold 7 - Train Accuracy: 0.9556, Precision: 0.9556, Recall: 0.9556, F1 Score: 0.9556\n",
      "Fold 7 - Test Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Fold 8 - Train Accuracy: 0.9556, Precision: 0.9556, Recall: 0.9556, F1 Score: 0.9556\n",
      "Fold 8 - Test Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
      "Fold 9 - Train Accuracy: 0.9630, Precision: 0.9631, Recall: 0.9630, F1 Score: 0.9630\n",
      "Fold 9 - Test Accuracy: 0.9333, Precision: 0.9444, Recall: 0.9333, F1 Score: 0.9327\n",
      "Fold 10 - Train Accuracy: 0.9704, Precision: 0.9704, Recall: 0.9704, F1 Score: 0.9704\n",
      "Fold 10 - Test Accuracy: 0.8667, Precision: 0.9048, Recall: 0.8667, F1 Score: 0.8611\n",
      "\n",
      "Mean CV Accuracy: 0.9533 (+/- 0.0854)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#print(iris)\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create a Naive Bayes Classifier (Gaussian Naive Bayes)\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score for training set\n",
    "accuracy_train = metrics.accuracy_score(y_train, y_pred_train)\n",
    "precision_train = metrics.precision_score(y_train, y_pred_train, average='weighted')\n",
    "recall_train = metrics.recall_score(y_train, y_pred_train, average='weighted')\n",
    "f1_score_train = metrics.f1_score(y_train, y_pred_train, average='weighted')\n",
    "\n",
    "print(f\"Training Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Training Precision: {precision_train:.4f}\")\n",
    "print(f\"Training Recall: {recall_train:.4f}\")\n",
    "print(f\"Training F1 Score: {f1_score_train:.4f}\")\n",
    "\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score for test set\n",
    "accuracy_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "precision_test = metrics.precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = metrics.recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_score_test = metrics.f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_test:.4f}\")\n",
    "print(f\"Test Precision: {precision_test:.4f}\")\n",
    "print(f\"Test Recall: {recall_test:.4f}\")\n",
    "print(f\"Test F1 Score: {f1_score_test:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X_scaled, y, cv=10, scoring='accuracy')\n",
    "cv_predictions = cross_val_predict(clf, X_scaled, y, cv=10)\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score for each fold in cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(StratifiedKFold(n_splits=10, shuffle=True, random_state=42).split(X_scaled, y)):\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    \n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_train = clf.predict(X_train_fold)\n",
    "    y_pred_test_fold = clf.predict(X_test_fold)\n",
    "    \n",
    "    accuracy_train = metrics.accuracy_score(y_train_fold, y_pred_train)\n",
    "    precision_train = metrics.precision_score(y_train_fold, y_pred_train, average='weighted')\n",
    "    recall_train = metrics.recall_score(y_train_fold, y_pred_train, average='weighted')\n",
    "    f1_score_train = metrics.f1_score(y_train_fold, y_pred_train, average='weighted')\n",
    "    \n",
    "    accuracy_test_fold = metrics.accuracy_score(y_test_fold, y_pred_test_fold)\n",
    "    precision_test_fold = metrics.precision_score(y_test_fold, y_pred_test_fold, average='weighted')\n",
    "    recall_test_fold = metrics.recall_score(y_test_fold, y_pred_test_fold, average='weighted')\n",
    "    f1_score_test_fold = metrics.f1_score(y_test_fold, y_pred_test_fold, average='weighted')\n",
    "    \n",
    "    print(f\"Fold {fold + 1} - Train Accuracy: {accuracy_train:.4f}, Precision: {precision_train:.4f}, Recall: {recall_train:.4f}, F1 Score: {f1_score_train:.4f}\")\n",
    "    print(f\"Fold {fold + 1} - Test Accuracy: {accuracy_test_fold:.4f}, Precision: {precision_test_fold:.4f}, Recall: {recall_test_fold:.4f}, F1 Score: {f1_score_test_fold:.4f}\")\n",
    "\n",
    "# Calculate mean and standard deviation of cross-validation scores\n",
    "print(f\"\\nMean CV Accuracy: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores) * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
